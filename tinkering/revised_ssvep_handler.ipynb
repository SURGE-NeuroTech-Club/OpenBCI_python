{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from brainflow.board_shim import BoardShim\n",
    "from scipy.signal import butter, lfilter, welch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mvlearn.embed import CCA\n",
    "\n",
    "matplotlib.use('Agg')  # Use a non-GUI backend\n",
    "\n",
    "class PreProcess:\n",
    "    \"\"\"\n",
    "    A class to handle preprocessing of EEG data for SSVEP BCI systems.\n",
    "\n",
    "    Attributes:\n",
    "        board (BoardShim): The BrainFlow board object for EEG data acquisition.\n",
    "        segment_duration (float): The duration of each data segment in seconds.\n",
    "        sampling_rate (int): The sampling rate of the EEG data.\n",
    "        n_samples (int): The number of samples in each data segment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, board, segment_duration):\n",
    "        \"\"\"\n",
    "        Initializes the PreProcess class with the given parameters.\n",
    "\n",
    "        Args:\n",
    "            board (BoardShim): The BrainFlow board object for EEG data acquisition.\n",
    "            segment_duration (float): The duration of each data segment in seconds.\n",
    "        \"\"\"\n",
    "        self.board = board\n",
    "        self.segment_duration = segment_duration\n",
    "        self.sampling_rate = BoardShim.get_sampling_rate(self.board.board_id)\n",
    "        self.n_samples = int(self.sampling_rate * self.segment_duration)\n",
    "  \n",
    "    def get_segment(self):\n",
    "        \"\"\"\n",
    "        Retrieves the latest segment of EEG data.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The latest segment of EEG data, or None if insufficient data.\n",
    "        \"\"\"\n",
    "        data = self.board.get_current_board_data(self.n_samples)\n",
    "        if data.shape[1] >= self.n_samples:\n",
    "            segment = data[:, -self.n_samples:]\n",
    "            return segment\n",
    "        return None\n",
    "\n",
    "    def filter_data(self, data):\n",
    "        \"\"\"\n",
    "        Applies a bandpass filter to the EEG data.\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The EEG data to be filtered.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The filtered EEG data.\n",
    "        \"\"\"\n",
    "        lowcut = 0.5  # Example low cut frequency in Hz\n",
    "        highcut = 30.0  # Example high cut frequency in Hz\n",
    "        filtered_data = np.apply_along_axis(self.bandpass_filter, 1, data, lowcut, highcut, self.sampling_rate)\n",
    "        return filtered_data\n",
    "\n",
    "    def bandpass_filter(self, data, lowcut, highcut, fs, order=5):\n",
    "        \"\"\"\n",
    "        Applies a bandpass filter to a single channel of EEG data.\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The EEG data for a single channel.\n",
    "            lowcut (float): The low cut frequency of the filter in Hz.\n",
    "            highcut (float): The high cut frequency of the filter in Hz.\n",
    "            fs (int): The sampling rate of the data in Hz.\n",
    "            order (int): The order of the filter.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The bandpass filtered EEG data.\n",
    "        \"\"\"\n",
    "        nyquist = 0.5 * fs\n",
    "        low = lowcut / nyquist\n",
    "        high = highcut / nyquist\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    def extract_features(self, data):\n",
    "        \"\"\"\n",
    "        Extracts features from the EEG data.\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The EEG data from which to extract features.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The extracted features, including mean and standard deviation for each channel.\n",
    "        \"\"\"\n",
    "        features = np.vstack((data.mean(axis=1), data.std(axis=1))).T\n",
    "        return features\n",
    "\n",
    "    def save_data(self, data, filename):\n",
    "        \"\"\"\n",
    "        Saves the EEG data to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The EEG data to be saved.\n",
    "            filename (str): The name of the file to save the data to.\n",
    "        \"\"\"\n",
    "        np.savetxt(filename, data, delimiter=',')\n",
    "\n",
    "class SSVEP_SNR:\n",
    "    \"\"\"\n",
    "    A class to calculate and plot Signal-to-Noise Ratio (SNR) for SSVEP signals.\n",
    "    \"\"\"\n",
    "    def __init__(self, signal, fs, noise_bandwidth=1):\n",
    "        self.signal = signal\n",
    "        self.fs = fs\n",
    "        self.noise_bandwidth = noise_bandwidth\n",
    "\n",
    "    def calculate_psd(self):\n",
    "        freqs, psd = welch(self.signal, self.fs, nperseg=1024)\n",
    "        return freqs, psd\n",
    "\n",
    "    def calculate_snr(self):\n",
    "        freqs, psd = self.calculate_psd()\n",
    "        snr = np.zeros_like(psd)\n",
    "        for i in range(len(freqs)):\n",
    "            noise_range = np.logical_and(freqs >= freqs[i] - self.noise_bandwidth, freqs <= freqs[i] + self.noise_bandwidth)\n",
    "            noise_range[i] = False  # Exclude the signal frequency itself\n",
    "            signal_power = psd[i]\n",
    "            noise_power = np.mean(psd[noise_range])\n",
    "            snr[i] = 10 * np.log10(signal_power / noise_power)\n",
    "        return freqs, snr\n",
    "\n",
    "    def plot_snr(self, filename='snr_plot.png', fmin=1.0, fmax=50.0):\n",
    "        freqs, psd = self.calculate_psd()\n",
    "        freqs, snr = self.calculate_snr()\n",
    "        freq_range = range(np.where(np.floor(freqs) == fmin)[0][0], np.where(np.ceil(freqs) == fmax)[0][0])\n",
    "        psd_db = 10 * np.log10(psd)\n",
    "        fig, axes = plt.subplots(2, 1, sharex=\"all\", sharey=\"none\", figsize=(8, 5))\n",
    "        axes[0].plot(freqs[freq_range], psd_db[freq_range], color=\"b\")\n",
    "        axes[0].fill_between(freqs[freq_range], psd_db[freq_range], color=\"b\", alpha=0.2)\n",
    "        axes[0].set(title=\"PSD Spectrum\", ylabel=\"Power Spectral Density [dB]\")\n",
    "        axes[1].plot(freqs[freq_range], snr[freq_range], color=\"r\")\n",
    "        axes[1].fill_between(freqs[freq_range], snr[freq_range], color=\"r\", alpha=0.2)\n",
    "        axes[1].set(title=\"SNR Spectrum\", xlabel=\"Frequency [Hz]\", ylabel=\"SNR [dB]\", ylim=[-2, 30], xlim=[fmin, fmax])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "class ClassifySSVEP:\n",
    "    def __init__(self, frequencies, harmonics, sampling_rate, n_samples, stack_harmonics=True):\n",
    "        self.frequencies = frequencies\n",
    "        self.harmonics = harmonics\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.n_samples = n_samples\n",
    "        self.stack_harmonics = stack_harmonics\n",
    "        self.reference_signals = self._generate_reference_signals()\n",
    "\n",
    "    def _generate_reference_signals(self):\n",
    "        reference_signals = {}\n",
    "        time = np.linspace(0, self.n_samples / self.sampling_rate, self.n_samples, endpoint=False)\n",
    "        for freq in self.frequencies:\n",
    "            signals = []\n",
    "            for harmon in self.harmonics:\n",
    "                sine_wave = np.sin(2 * np.pi * harmon * freq * time)\n",
    "                cosine_wave = np.cos(2 * np.pi * harmon * freq * time)\n",
    "                signals.append(sine_wave)\n",
    "                signals.append(cosine_wave)\n",
    "            if self.stack_harmonics:\n",
    "                reference_signals[freq] = np.vstack(signals).T\n",
    "            else:\n",
    "                reference_signals[freq] = np.array(signals)\n",
    "        return reference_signals\n",
    "\n",
    "    def get_reference_signals(self, frequency):\n",
    "        return self.reference_signals.get(frequency, None)\n",
    "\n",
    "    def cca_analysis(self, eeg_data):\n",
    "        cca = CCA(n_components=1)\n",
    "        max_corr = 0\n",
    "        target_freq = None\n",
    "        for freq, ref in self.reference_signals.items():\n",
    "            if self.stack_harmonics:\n",
    "                if eeg_data.shape[1] != ref.shape[0]:\n",
    "                    raise ValueError(\"EEG data and reference signals must have the same number of samples\")\n",
    "                cca.fit([eeg_data.T, ref])\n",
    "                U, V = cca.transform([eeg_data.T, ref])\n",
    "            else:\n",
    "                U, V = None, None\n",
    "                if eeg_data.shape[1] != ref.shape[1]:\n",
    "                    raise ValueError(\"EEG data and reference signals must have the same number of samples\")\n",
    "                for i in range(ref.shape[0] // 2):\n",
    "                    cca.fit([eeg_data.T, ref[2*i:2*i+2, :].T])\n",
    "                    U_tmp, V_tmp = cca.transform([eeg_data.T, ref[2*i:2*i+2, :].T])\n",
    "                    if U is None:\n",
    "                        U, V = U_tmp, V_tmp\n",
    "                    else:\n",
    "                        U = np.hstack((U, U_tmp))\n",
    "                        V = np.hstack((V, V_tmp))\n",
    "            corr = np.corrcoef(U[:, 0], V[:, 0])[0, 1]\n",
    "            if corr > max_corr:\n",
    "                max_corr = corr\n",
    "                target_freq = freq\n",
    "        return target_freq, max_corr\n",
    "\n",
    "    def check_snr(self, eeg_data):\n",
    "        signal = eeg_data.flatten()  # Assuming eeg_data is 2D: (n_channels, n_samples)\n",
    "        snr_calculator = SSVEP_SNR(signal, self.sampling_rate)\n",
    "        freqs, snr_values = snr_calculator.calculate_snr()\n",
    "        snr_results = {}\n",
    "        for freq in self.frequencies:\n",
    "            target_idx = np.argmin(np.abs(freqs - freq))\n",
    "            snr_results[freq] = snr_values[target_idx]\n",
    "        return snr_results\n",
    "\n",
    "    def visualize_ssvep(self, eeg_data, filename='ssvep_visualization.png'):\n",
    "        snr_calculator = SSVEP_SNR(eeg_data.flatten(), self.sampling_rate)\n",
    "        freqs, snr = snr_calculator.calculate_snr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot(freqs, snr, label='SNR')\n",
    "        for freq in self.frequencies:\n",
    "            ax.axvline(freq, color='r', linestyle='--', label=f'Target Frequency: {freq} Hz')\n",
    "        \n",
    "        ax.set(title='SSVEP Signal Visualization', xlabel='Frequency (Hz)', ylabel='SNR (dB)')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "class FBCCA:\n",
    "    def __init__(self, frequencies, harmonics, sampling_rate, n_samples, num_subbands=5):\n",
    "        self.frequencies = frequencies\n",
    "        self.harmonics = harmonics\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.n_samples = n_samples\n",
    "        self.num_subbands = num_subbands\n",
    "        self.reference_signals = self._generate_reference_signals()\n",
    "        self.filters = self._generate_filters()\n",
    "\n",
    "    def _generate_reference_signals(self):\n",
    "        reference_signals = {}\n",
    "        time = np.linspace(0, self.n_samples / self.sampling_rate, self.n_samples, endpoint=False)\n",
    "        for freq in self.frequencies:\n",
    "            signals = []\n",
    "            for harmon in self.harmonics:\n",
    "                sine_wave = np.sin(2 * np.pi * harmon * freq * time)\n",
    "                cosine_wave = np.cos(2 * np.pi * harmon * freq * time)\n",
    "                signals.append(sine_wave)\n",
    "                signals.append(cosine_wave)\n",
    "            reference_signals[freq] = np.vstack(signals).T\n",
    "        return reference_signals\n",
    "\n",
    "    def _generate_filters(self):\n",
    "        filters = []\n",
    "        nyquist = 0.5 * self.sampling_rate\n",
    "        low = 6 / nyquist\n",
    "        high = 40 / nyquist\n",
    "        subband_width = (high - low) / self.num_subbands\n",
    "        for i in range(self.num_subbands):\n",
    "            band = [low + i * subband_width, low + (i + 1) * subband_width]\n",
    "            if band[1] > 1.0:\n",
    "                band[1] = 1.0\n",
    "            b, a = butter(4, band, btype='band')\n",
    "            filters.append((b, a))\n",
    "        return filters\n",
    "\n",
    "    def filter_data(self, data):\n",
    "        filtered_data = []\n",
    "        for b, a in self.filters:\n",
    "            filtered_data.append(filt(b, a, data, axis=-1))\n",
    "        return np.array(filtered_data)\n",
    "\n",
    "    def fbcca_analysis(self, eeg_data):\n",
    "        max_corr = 0\n",
    "        target_freq = None\n",
    "        for freq, ref in self.reference_signals.items():\n",
    "            corr = 0\n",
    "            filtered_data = self.filter_data(eeg_data)\n",
    "            for subband_data in filtered_data:\n",
    "                cca = CCA(n_components=1)\n",
    "                cca.fit([subband_data.T, ref])\n",
    "                U, V = cca.transform([subband_data.T, ref])\n",
    "                subband_corr = np.corrcoef(U[:, 0], V[:, 0])[0, 1]\n",
    "                corr += subband_corr\n",
    "            corr /= self.num_subbands\n",
    "            if corr > max_corr:\n",
    "                max_corr = corr\n",
    "                target_freq = freq\n",
    "        return target_freq, max_corr\n",
    "\n",
    "    def visualize_ssvep(self, eeg_data, filename='fbcca_ssvep_visualization.png'):\n",
    "        snr_calculator = SSVEP_SNR(eeg_data.flatten(), self.sampling_rate)\n",
    "        freqs, snr = snr_calculator.calculate_snr()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.plot(freqs, snr, label='SNR')\n",
    "        for freq in self.frequencies:\n",
    "            ax.axvline(freq, color='r', linestyle='--', label=f'Target Frequency: {freq} Hz')\n",
    "        \n",
    "        ax.set(title='FBCCA SSVEP Signal Visualization', xlabel='Frequency (Hz)', ylabel='SNR (dB)')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 15000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('sim_ssvep_data.npy')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frequency with stacked harmonics: 15.25 Hz with correlation: 0.99747232667337\n",
      "Detected frequency without stacked harmonics: 15.25 Hz with correlation: 0.9974588977170615\n",
      "Frequency: 9.25 Hz, SNR: -2.99 dB\n",
      "Frequency: 11.25 Hz, SNR: 2.60 dB\n",
      "Frequency: 13.25 Hz, SNR: 0.14 dB\n",
      "Frequency: 15.25 Hz, SNR: 9.09 dB\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'filt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m fbcca_classifier \u001b[38;5;241m=\u001b[39m FBCCA(frequencies, harmonics, sampling_rate, n_samples)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Perform FBCCA analysis and visualize results\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m target_freq_fbcca, max_corr_fbcca \u001b[38;5;241m=\u001b[39m \u001b[43mfbcca_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfbcca_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFBCCA - Target Frequency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_freq_fbcca\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Hz, Max Correlation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_corr_fbcca\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m fbcca_classifier\u001b[38;5;241m.\u001b[39mvisualize_ssvep(eeg_data, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfbcca_ssvep_visualization.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 276\u001b[0m, in \u001b[0;36mFBCCA.fbcca_analysis\u001b[1;34m(self, eeg_data)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m freq, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_signals\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    275\u001b[0m     corr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 276\u001b[0m     filtered_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subband_data \u001b[38;5;129;01min\u001b[39;00m filtered_data:\n\u001b[0;32m    278\u001b[0m         cca \u001b[38;5;241m=\u001b[39m CCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 268\u001b[0m, in \u001b[0;36mFBCCA.filter_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    266\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b, a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters:\n\u001b[1;32m--> 268\u001b[0m     filtered_data\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfilt\u001b[49m(b, a, data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(filtered_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filt' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    frequencies = [9.25, 11.25, 13.25, 15.25]\n",
    "    harmonics = np.arange(1, 5)\n",
    "    sampling_rate = 250\n",
    "    n_samples = 1000\n",
    "\n",
    "    # Initialize with stacking harmonics\n",
    "    ssvep_harmonics_stacked = ClassifySSVEP(frequencies, harmonics, sampling_rate, n_samples, stack_harmonics=True)\n",
    "\n",
    "    # Initialize without stacking harmonics\n",
    "    ssvep_harmonics_not_stacked = ClassifySSVEP(frequencies, harmonics, sampling_rate, n_samples, stack_harmonics=False)\n",
    "\n",
    "    # Example EEG data (randomly generated for illustration purposes)\n",
    "    eeg_data = data[:, 9000:10000]\n",
    "\n",
    "    # Perform CCA analysis with stacked harmonics\n",
    "    detected_freq_stacked, correlation_stacked = ssvep_harmonics_stacked.cca_analysis(eeg_data)\n",
    "    print(f\"Detected frequency with stacked harmonics: {detected_freq_stacked} Hz with correlation: {correlation_stacked}\")\n",
    "\n",
    "    # Perform CCA analysis without stacked harmonics\n",
    "    detected_freq_not_stacked, correlation_not_stacked = ssvep_harmonics_not_stacked.cca_analysis(eeg_data)\n",
    "    print(f\"Detected frequency without stacked harmonics: {detected_freq_not_stacked} Hz with correlation: {correlation_not_stacked}\")\n",
    "    \n",
    "    snr_results = ssvep_harmonics_stacked.check_snr(eeg_data)\n",
    "    for freq, snr in snr_results.items():\n",
    "        print(f\"Frequency: {freq} Hz, SNR: {snr:.2f} dB\")\n",
    "\n",
    "    snr_calculator = SSVEP_SNR(eeg_data.flatten(), sampling_rate)\n",
    "    snr_calculator.plot_snr('snr_plot.png', fmin=1.0, fmax=50.0)\n",
    "    \n",
    "    # Initialize FBCCA class\n",
    "    fbcca_classifier = FBCCA(frequencies, harmonics, sampling_rate, n_samples)\n",
    "\n",
    "    # Perform FBCCA analysis and visualize results\n",
    "    target_freq_fbcca, max_corr_fbcca = fbcca_classifier.fbcca_analysis(eeg_data)\n",
    "    print(f\"FBCCA - Target Frequency: {target_freq_fbcca} Hz, Max Correlation: {max_corr_fbcca}\")\n",
    "\n",
    "    fbcca_classifier.visualize_ssvep(eeg_data, filename='fbcca_ssvep_visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
